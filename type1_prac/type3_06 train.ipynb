{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16116c79",
   "metadata": {},
   "source": [
    "## 06. 적합도 검정\n",
    "\n",
    "한 도시의 운전자 1,000명을 대상으로 교통사고 경험 수를 조사했다. 1회: 550명, 2회 250명, 3회 100명, 4회 70명, 5회 이상 30명이다. 전국적으로 조사된 데이터에 따르면 운전자들의 교통사고 경험 수 분포는 다음과 같다. 1회: 60%, 2회: 25%, 3회: 8%, 4회: 5%, 5회 이상: 2%다. 이 도시 운전자들의 교통사고 경험 수 분포가 전국적인 경향을 따르는지 검정하시오. (유의수준 0.05)\n",
    "* 귀무가설($H_0$): 이 도시의 교통사고 경험 수 분포는 전국적인 경향을 따른다.\n",
    "* 대립가설($H_1$): 이 도시의 교통사고 경험 수 분포는 전국적인 경향을 따르지 않는다.  \n",
    "\n",
    "|구분|경험 수|전국적인 경향(%)|\n",
    "|------|---|---|\n",
    "|1회|550|60%|\n",
    "|2회|250|25%|\n",
    "|3회|100|8%|\n",
    "|4회|70|5%|\n",
    "|5회|30|2%|\n",
    "\n",
    "1. 이 도시의 교통사고 경험자 중 5회 이상의 비율을 0과 1 사이로 구하시오.\n",
    "2. 이 도시 운전자들의 교통사고 경험 수 분포가 전국적인 경향을 따르는지 검정하기 위한 검정 통계량을 구하시오.\n",
    "3. 위 통계량에 대한 p-value를 구하시오.\n",
    "4. 위의 검정 결과를 유의수준 0.05하에서 귀물가설을 기준으로 채택/기각 중 선택해 입력하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05c32bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n"
     ]
    }
   ],
   "source": [
    "# 1. 이 도시의 교통사고 경험자 중 5회 이상의 비율\n",
    "\n",
    "print(30/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13ebed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function chisquare in module scipy.stats._stats_py:\n",
      "\n",
      "chisquare(f_obs, f_exp=None, ddof=0, axis=0, *, sum_check=True, nan_policy='propagate', keepdims=False)\n",
      "    Perform Pearson's chi-squared test.\n",
      "\n",
      "    Pearson's chi-squared test [1]_ is a goodness-of-fit test for a multinomial\n",
      "    distribution with given probabilities; that is, it assesses the null hypothesis\n",
      "    that the observed frequencies (counts) are obtained by independent\n",
      "    sampling of *N* observations from a categorical distribution with given\n",
      "    expected frequencies.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    f_obs : array_like\n",
      "        Observed frequencies in each category.\n",
      "    f_exp : array_like, optional\n",
      "        Expected frequencies in each category. By default, the categories are\n",
      "        assumed to be equally likely.\n",
      "    ddof : int, optional\n",
      "        \"Delta degrees of freedom\": adjustment to the degrees of freedom\n",
      "        for the p-value.  The p-value is computed using a chi-squared\n",
      "        distribution with ``k - 1 - ddof`` degrees of freedom, where ``k``\n",
      "        is the number of categories.  The default value of `ddof` is 0.\n",
      "    axis : int or None, default: 0\n",
      "        If an int, the axis of the input along which to compute the statistic.\n",
      "        The statistic of each axis-slice (e.g. row) of the input will appear in a\n",
      "        corresponding element of the output.\n",
      "        If ``None``, the input will be raveled before computing the statistic.\n",
      "    sum_check : bool, optional\n",
      "        Whether to perform a check that ``sum(f_obs) - sum(f_exp) == 0``. If True,\n",
      "        (default) raise an error when the relative difference exceeds the square root\n",
      "        of the precision of the data type. See Notes for rationale and possible\n",
      "        exceptions.\n",
      "    nan_policy : {'propagate', 'omit', 'raise'}\n",
      "        Defines how to handle input NaNs.\n",
      "\n",
      "        - ``propagate``: if a NaN is present in the axis slice (e.g. row) along\n",
      "          which the  statistic is computed, the corresponding entry of the output\n",
      "          will be NaN.\n",
      "        - ``omit``: NaNs will be omitted when performing the calculation.\n",
      "          If insufficient data remains in the axis slice along which the\n",
      "          statistic is computed, the corresponding entry of the output will be\n",
      "          NaN.\n",
      "        - ``raise``: if a NaN is present, a ``ValueError`` will be raised.\n",
      "    keepdims : bool, default: False\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    res: Power_divergenceResult\n",
      "        An object containing attributes:\n",
      "\n",
      "        statistic : float or ndarray\n",
      "            The chi-squared test statistic.  The value is a float if `axis` is\n",
      "            None or `f_obs` and `f_exp` are 1-D.\n",
      "        pvalue : float or ndarray\n",
      "            The p-value of the test.  The value is a float if `ddof` and the\n",
      "            result attribute `statistic` are scalars.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "\n",
      "    :func:`scipy.stats.power_divergence`\n",
      "        ..\n",
      "    :func:`scipy.stats.fisher_exact`\n",
      "        Fisher exact test on a 2x2 contingency table.\n",
      "    :func:`scipy.stats.barnard_exact`\n",
      "        An unconditional exact test. An alternative to chi-squared test for small sample sizes.\n",
      "    :ref:`hypothesis_chisquare`\n",
      "        Extended example\n",
      "\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    This test is invalid when the observed or expected frequencies in each\n",
      "    category are too small.  A typical rule is that all of the observed\n",
      "    and expected frequencies should be at least 5. According to [2]_, the\n",
      "    total number of observations is recommended to be greater than 13,\n",
      "    otherwise exact tests (such as Barnard's Exact test) should be used\n",
      "    because they do not overreject.\n",
      "\n",
      "    The default degrees of freedom, k-1, are for the case when no parameters\n",
      "    of the distribution are estimated. If p parameters are estimated by\n",
      "    efficient maximum likelihood then the correct degrees of freedom are\n",
      "    k-1-p. If the parameters are estimated in a different way, then the\n",
      "    dof can be between k-1-p and k-1. However, it is also possible that\n",
      "    the asymptotic distribution is not chi-square, in which case this test\n",
      "    is not appropriate.\n",
      "\n",
      "    For Pearson's chi-squared test, the total observed and expected counts must match\n",
      "    for the p-value to accurately reflect the probability of observing such an extreme\n",
      "    value of the statistic under the null hypothesis.\n",
      "    This function may be used to perform other statistical tests that do not require\n",
      "    the total counts to be equal. For instance, to test the null hypothesis that\n",
      "    ``f_obs[i]`` is Poisson-distributed with expectation ``f_exp[i]``, set ``ddof=-1``\n",
      "    and ``sum_check=False``. This test follows from the fact that a Poisson random\n",
      "    variable with mean and variance ``f_exp[i]`` is approximately normal with the\n",
      "    same mean and variance; the chi-squared statistic standardizes, squares, and sums\n",
      "    the observations; and the sum of ``n`` squared standard normal variables follows\n",
      "    the chi-squared distribution with ``n`` degrees of freedom.\n",
      "\n",
      "    Beginning in SciPy 1.9, ``np.matrix`` inputs (not recommended for new\n",
      "    code) are converted to ``np.ndarray`` before the calculation is performed. In\n",
      "    this case, the output will be a scalar or ``np.ndarray`` of appropriate shape\n",
      "    rather than a 2D ``np.matrix``. Similarly, while masked elements of masked\n",
      "    arrays are ignored, the output will be a scalar or ``np.ndarray`` rather than a\n",
      "    masked array with ``mask=False``.\n",
      "\n",
      "    `chisquare` has experimental support for Python Array API Standard compatible\n",
      "    backends in addition to NumPy. Please consider testing these features\n",
      "    by setting an environment variable ``SCIPY_ARRAY_API=1`` and providing\n",
      "    CuPy, PyTorch, JAX, or Dask arrays as array arguments. The following\n",
      "    combinations of backend and device (or other capability) are supported.\n",
      "\n",
      "    ====================  ====================  ====================\n",
      "    Library               CPU                   GPU\n",
      "    ====================  ====================  ====================\n",
      "    NumPy                 ✅                     n/a\n",
      "    CuPy                  n/a                   ✅\n",
      "    PyTorch               ✅                     ✅\n",
      "    JAX                   ⚠️ no JIT             ⚠️ no JIT\n",
      "    Dask                  ⚠️ computes graph     n/a\n",
      "    ====================  ====================  ====================\n",
      "\n",
      "    See :ref:`dev-arrayapi` for more information.\n",
      "\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] \"Pearson's chi-squared test\".\n",
      "           *Wikipedia*. https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test\n",
      "    .. [2] Pearson, Karl. \"On the criterion that a given system of deviations from the probable\n",
      "           in the case of a correlated system of variables is such that it can be reasonably\n",
      "           supposed to have arisen from random sampling\", Philosophical Magazine. Series 5. 50\n",
      "           (1900), pp. 157-175.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    When only the mandatory `f_obs` argument is given, it is assumed that the\n",
      "    expected frequencies are uniform and given by the mean of the observed\n",
      "    frequencies:\n",
      "\n",
      "    >>> import numpy as np\n",
      "    >>> from scipy.stats import chisquare\n",
      "    >>> chisquare([16, 18, 16, 14, 12, 12])\n",
      "    Power_divergenceResult(statistic=2.0, pvalue=0.84914503608460956)\n",
      "\n",
      "    The optional `f_exp` argument gives the expected frequencies.\n",
      "\n",
      "    >>> chisquare([16, 18, 16, 14, 12, 12], f_exp=[16, 16, 16, 16, 16, 8])\n",
      "    Power_divergenceResult(statistic=3.5, pvalue=0.62338762774958223)\n",
      "\n",
      "    When `f_obs` is 2-D, by default the test is applied to each column.\n",
      "\n",
      "    >>> obs = np.array([[16, 18, 16, 14, 12, 12], [32, 24, 16, 28, 20, 24]]).T\n",
      "    >>> obs.shape\n",
      "    (6, 2)\n",
      "    >>> chisquare(obs)\n",
      "    Power_divergenceResult(statistic=array([2.        , 6.66666667]), pvalue=array([0.84914504, 0.24663415]))\n",
      "\n",
      "    By setting ``axis=None``, the test is applied to all data in the array,\n",
      "    which is equivalent to applying the test to the flattened array.\n",
      "\n",
      "    >>> chisquare(obs, axis=None)\n",
      "    Power_divergenceResult(statistic=23.31034482758621, pvalue=0.015975692534127565)\n",
      "    >>> chisquare(obs.ravel())\n",
      "    Power_divergenceResult(statistic=23.310344827586206, pvalue=0.01597569253412758)\n",
      "\n",
      "    `ddof` is the change to make to the default degrees of freedom.\n",
      "\n",
      "    >>> chisquare([16, 18, 16, 14, 12, 12], ddof=1)\n",
      "    Power_divergenceResult(statistic=2.0, pvalue=0.7357588823428847)\n",
      "\n",
      "    The calculation of the p-values is done by broadcasting the\n",
      "    chi-squared statistic with `ddof`.\n",
      "\n",
      "    >>> chisquare([16, 18, 16, 14, 12, 12], ddof=[0, 1, 2])\n",
      "    Power_divergenceResult(statistic=2.0, pvalue=array([0.84914504, 0.73575888, 0.5724067 ]))\n",
      "\n",
      "    `f_obs` and `f_exp` are also broadcast.  In the following, `f_obs` has\n",
      "    shape (6,) and `f_exp` has shape (2, 6), so the result of broadcasting\n",
      "    `f_obs` and `f_exp` has shape (2, 6).  To compute the desired chi-squared\n",
      "    statistics, we use ``axis=1``:\n",
      "\n",
      "    >>> chisquare([16, 18, 16, 14, 12, 12],\n",
      "    ...           f_exp=[[16, 16, 16, 16, 16, 8], [8, 20, 20, 16, 12, 12]],\n",
      "    ...           axis=1)\n",
      "    Power_divergenceResult(statistic=array([3.5 , 9.25]), pvalue=array([0.62338763, 0.09949846]))\n",
      "\n",
      "    For a more detailed example, see :ref:`hypothesis_chisquare`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "help(stats.chisquare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b8d206e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=np.float64(22.166666666666668), pvalue=np.float64(0.00018567620386641427))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frq = [550, 250, 100, 70, 30]\n",
    "exp = [1000*0.6, 1000*0.25, 1000 *0.08, 1000*0.05, 1000*0.02]\n",
    "\n",
    "stats.chisquare(frq, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e587c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
